{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2250c6-4cd7-4de5-bdde-f3c7f51775e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '8842281e1d1347389f2ab93d60773d4d', 'timestamp': '2017-08-30', 'review_sentences': [[0, 'This is a special book.'], [0, 'It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind.'], [0, 'This is what I love about good science fiction - it pushes your thinking about where things can go.'], [0, \"It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I've read.\"], [0, 'For instance the intermixing of Chinese revolutionary history - how they kept accusing people of being \"reactionaries\", etc.'], [0, 'It is a book about science, and aliens.'], [0, 'The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell.'], [1, 'Though when it got to folding protons into 8 dimensions I think he was just making stuff up - interesting to think about though.'], [1, 'But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned?'], [1, 'That part of the book was a bit dark - I would like to think human reaction to discovering alien civilization that is hostile would be more like Enders Game where we would band together.'], [1, 'I did like how the book unveiled the Trisolaran culture through the game.'], [1, \"It was a smart way to build empathy with them and also understand what they've gone through across so many centuries.\"], [1, 'And who know a 3 body problem was an unsolvable math problem?'], [1, \"But I still don't get who made the game - maybe that will come in the next book.\"], [1, 'I loved this quote:'], [1, '\"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists?'], [1, 'How many neutrons and electrons?'], [1, 'Probably no fewer than a hundred million.'], [1, 'Every collision was probably the end of the civilizations and intelligences in a microcosmos.'], [1, 'In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons.'], [1, 'Also, a high-energy cosmic ray entering the atmosphere may destroy thousands of such miniature universes....\"']], 'rating': 5, 'has_spoiler': True, 'book_id': '18245960', 'review_id': 'dfdbb7b0eb5a7e4c26d59a937e2e5feb'}\n",
      "Training Data Size:  51515\n",
      "Testing Data Size:  15504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import scipy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import scipy.sparse\n",
    "\n",
    "# Path to the .json.gz file\n",
    "file_path = 'goodreads_reviews_spoiler.json.gz'\n",
    "ct = 0\n",
    "\n",
    "# Open and read the file line by line\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        try:\n",
    "            ct += 1\n",
    "            review = json.loads(line)\n",
    "            data.append(review)\n",
    "            if ct == 70000:\n",
    "                break\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {e}\")\n",
    "\n",
    "# Example: Print the first parsed review\n",
    "if data:\n",
    "    print(data[0])\n",
    "else:\n",
    "    print(\"No data was parsed.\")\n",
    "\n",
    "\n",
    "train_size = 68000\n",
    "test_size = 1200\n",
    "\n",
    "ones_minus_zeros = 0\n",
    "ratingsTrain = []\n",
    "for i in data[:train_size]:\n",
    "    if i['has_spoiler']:\n",
    "        copy_to_upload = i\n",
    "        ones = sum([sent[0] for sent in copy_to_upload['review_sentences']])\n",
    "        non_spoilers = [sentence for sentence in i['review_sentences'] if sentence[0] == 0]\n",
    "        spoilers = [sentence for sentence in i['review_sentences'] if sentence[0] == 1]\n",
    "        selected_non_spoilers = []\n",
    "        if ones == 1:\n",
    "            k = min(3, len(non_spoilers))\n",
    "            selected_non_spoilers = random.choices(non_spoilers, k=k)\n",
    "            ones_minus_zeros -= (k-1)\n",
    "        elif ones == 2:\n",
    "            k = min(2, len(non_spoilers))\n",
    "            selected_non_spoilers = random.choices(non_spoilers, k=k)\n",
    "            ones_minus_zeros -= (k-2)\n",
    "        elif ones == 3:\n",
    "            k = min(1, len(non_spoilers))\n",
    "            selected_non_spoilers = random.choices(non_spoilers, k=k)\n",
    "            ones_minus_zeros += (3 - k)\n",
    "\n",
    "        else:\n",
    "            ones_minus_zeros += len(spoilers)\n",
    "            \n",
    "        new_sentences = selected_non_spoilers + spoilers\n",
    "        copy_to_upload['review_sentences'] = new_sentences\n",
    "\n",
    "        ratingsTrain.append(copy_to_upload)\n",
    "    elif ones_minus_zeros > 3:\n",
    "        copy_to_upload = i\n",
    "        if (ones_minus_zeros // 2) < len(i['review_sentences']):\n",
    "            selected_non_spoilers = random.choices(i['review_sentences'], k=ones_minus_zeros // 2)\n",
    "            ones_minus_zeros -= (ones_minus_zeros // 2)\n",
    "        else:\n",
    "            selected_non_spoilers = i['review_sentences']\n",
    "            ones_minus_zeros -= len(i['review_sentences'])\n",
    "        copy_to_upload['review_sentences'] = selected_non_spoilers\n",
    "        ratingsTrain.append(copy_to_upload)\n",
    "\n",
    "ratingsTest = data[train_size:train_size + test_size]\n",
    "tot_sent = 0\n",
    "for i in ratingsTrain:\n",
    "    tot_sent += len(i['review_sentences'])\n",
    "print(\"Training Data Size: \", tot_sent)\n",
    "tot_sent = 0\n",
    "for i in ratingsTest:\n",
    "    tot_sent += len(i['review_sentences'])\n",
    "print(\"Testing Data Size: \", tot_sent)\n",
    "\n",
    "\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "for d in data:\n",
    "    usersPerItem[d['book_id']].add(d['user_id'])\n",
    "    itemsPerUser[d['user_id']].add(d['book_id'])\n",
    "    ratingsPerUser[d['user_id']].append(d['rating'])\n",
    "    ratingsPerItem[d['book_id']].append(d['rating'])\n",
    "    for i in d['review_sentences']:\n",
    "        reviewsPerItem[d['book_id']].append(i[0])\n",
    "        reviewsPerUser[d['user_id']].append(i[0])\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for d in data:\n",
    "    bookCount[d['book_id']] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "PopularityBooks = [x[-1] for x in mostPopular]\n",
    "\n",
    "mostPopularUsers = [[len(value), key] for key, value in itemsPerUser.items()]\n",
    "mostPopularUsers.sort()\n",
    "mostPopularUsers.reverse()\n",
    "PopularityUsers = [x[-1] for x in mostPopularUsers]\n",
    "\n",
    "userIDs, itemIDs = {}, {}\n",
    "for d in data:\n",
    "    if d['user_id'] not in userIDs: userIDs[d['user_id']] = len(userIDs)\n",
    "    if d['book_id'] not in itemIDs: itemIDs[d['book_id']] = len(itemIDs)\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "Xui = scipy.sparse.lil_matrix((nUsers, nItems))\n",
    "for d in data:\n",
    "    Xui[userIDs[d['user_id']], itemIDs[d['book_id']]] = 1 \n",
    "\n",
    "Xui_csr = scipy.sparse.csr_matrix(Xui)\n",
    "\n",
    "book_popularity = np.sum(Xui_csr, axis=0).A1\n",
    "books_read_by_user = Xui_csr.sum(axis=1).A1\n",
    "\n",
    "spoiler_flat = [sum(sublist) for sublist in reviewsPerItem.values()]\n",
    "avg_ct_book_spoilers = sum(spoiler_flat) / len(spoiler_flat) if spoiler_flat else 0\n",
    "spoiler_flat_2 = [sum(sublist) for sublist in reviewsPerUser.values()]\n",
    "avg_ct_user_spoilers = sum(spoiler_flat_2) / len(spoiler_flat_2) if spoiler_flat_2 else 0\n",
    "flattened_1 = [item for sublist in ratingsPerItem.values() for item in sublist]\n",
    "ovr_avg_rating_item =  sum(flattened_1) / len(flattened_1) if flattened_1 else 0\n",
    "\n",
    "users = set(userIDs.keys())\n",
    "books = set(itemIDs.keys())\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval() \n",
    "\n",
    "def get_bert_embeddings(sentences):\n",
    "    tokens = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embeddings.numpy()\n",
    "\n",
    "def precompute_embeddings(data):\n",
    "    all_sentences = [sentence[1] for d in data for sentence in d['review_sentences']]\n",
    "    batch_size = 32\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(all_sentences), batch_size):\n",
    "        if i % (1280) == 0: \n",
    "            print(i)\n",
    "        batch = all_sentences[i:i + batch_size]\n",
    "        batch_embeddings = get_bert_embeddings(batch)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# Precompute embeddings for the training and testing sets\n",
    "#train_embeddings = precompute_embeddings(ratingsTrain + ratingsTest)\n",
    "#np.save('train_embeddings.npy', train_embeddings)  # Save embeddings for later use\n",
    "# Load precomputed embeddings\n",
    "train_embeddings = np.load('train_embeddings.npy')\n",
    "#test_embeddings = precompute_embeddings(ratingsTest)\n",
    "#np.save('test_embeddings.npy', test_embeddings)  # Save embeddings for later use\n",
    "test_embeddings = np.load('test_embeddings.npy')\n",
    "\n",
    "# Create data vectors\n",
    "def create_vector(review):\n",
    "    global users, books, avg_ct_book_spoilers, avg_ct_user_spoilers, ovr_avg_rating_item\n",
    "\n",
    "    u = review['user_id']\n",
    "    b = review['book_id']\n",
    "    sentence = review['BERT_data']\n",
    "    rating = review['rating']\n",
    "    length = review['length']\n",
    "\n",
    "    # Check if already seen book and/or user\n",
    "    book_in = b in books\n",
    "    user_in = u in users\n",
    "\n",
    "    if len(sentence) == 0:\n",
    "        sentence = np.zeros(768)  \n",
    "    temporal_feature = 0 \n",
    "    user_rating = rating if rating is not None else 0 \n",
    "\n",
    "    # Create vector based on if already seen book and/or user\n",
    "    if book_in and user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = book_pop * user_freq\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        \n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        \n",
    "    elif not user_in and not book_in:\n",
    "        book_pop = len(books)\n",
    "        user_freq = 0\n",
    "        pop_by_freq = 0\n",
    "        book_rank = len(books)\n",
    "        \n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        \n",
    "    elif not user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = 0\n",
    "        pop_by_freq = book_pop\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        \n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        \n",
    "    else:\n",
    "        book_pop = 0\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = user_freq\n",
    "        book_rank = len(PopularityBooks)\n",
    "        \n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "\n",
    "\n",
    "    # Combine features\n",
    "    vals = [\n",
    "        1, \n",
    "        pop_by_freq, \n",
    "        avg_rating_item,\n",
    "        book_rank,\n",
    "        length,\n",
    "        ct_book_spoilers,\n",
    "        ct_user_spoilers\n",
    "    ]\n",
    "    # Add BERT embeddings\n",
    "    vals.extend(sentence.tolist())\n",
    "    \n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c79c7f0-aa17-4586-841f-c4fef1b28f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train, test data to be vectorized by extracting each sentence and its related data\n",
    "x_train_pre = []\n",
    "y_train = []\n",
    "embedding_index = 0\n",
    "for d in ratingsTrain:\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    for i, sentence in enumerate(d['review_sentences']):\n",
    "        bert_embedding = train_embeddings[embedding_index] \n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        filtered_data['position'] = i\n",
    "        filtered_data['length'] = len(sentence)\n",
    "        x_train_pre.append(filtered_data)\n",
    "        y_train.append(sentence[0])\n",
    "        embedding_index += 1\n",
    "\n",
    "embedding_index = 0\n",
    "x_valid_pre = []\n",
    "y_valid = []\n",
    "for d in ratingsTest:\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    for i, sentence in enumerate(d['review_sentences']):\n",
    "        bert_embedding = test_embeddings[embedding_index] \n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        filtered_data['position'] = i\n",
    "        filtered_data['length'] = len(sentence)\n",
    "        x_valid_pre.append(filtered_data)\n",
    "        y_valid.append(sentence[0])\n",
    "        embedding_index += 1\n",
    "        \n",
    "# Get data vectors\n",
    "x_train = [create_vector(i) for i in x_train_pre]\n",
    "x_valid = [create_vector(i) for i in x_valid_pre]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_valid = np.array(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bf8aec-5d15-4307-aa3d-1bfa6e4daff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Info: TP  20870  TN  20868  FP  4888  FN  4889\n",
      "accuracy:  0.9118937048503611\n",
      "tp:  334 tn:  13804 fp:  1216 fn:  150\n",
      "F1:  0.32841691248770893\n",
      "AUC: 0.8961211497617502\n",
      "First spoiler position:  75\n",
      "Last spoiler position:  12104\n",
      "Average spoiler position:  1805.1797520661157\n",
      "Best threshold for F1: 0.09090909090909091, F1: 0.33184302036761054\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics function\n",
    "def get_metric(y_true, pred, scores):\n",
    "    corr = 0\n",
    "    tn, tp, fn, fp = 0,0,0,0\n",
    "    for guess, actual in zip(pred, y_true):\n",
    "        if guess == actual:\n",
    "            corr += 1\n",
    "            if guess == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        else:\n",
    "            if guess == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    if tp + fp == 0:\n",
    "        precision = 0\n",
    "        print(\"precision error, tp + fp = 0\")\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "        print(\"recall error, tp + fn = 0\")\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    print(\"accuracy: \", corr / len(pred))\n",
    "    print(\"tp: \", tp, \"tn: \", tn, \"fp: \", fp, \"fn: \", fn)\n",
    "    # Calculate F1 Score\n",
    "    if precision + recall == 0:\n",
    "        print(\"F1 error, precision + recall = 0\")\n",
    "    else:\n",
    "        print(\"F1: \", 2 * (precision * recall) / (precision + recall))\n",
    "    \n",
    "    auc = roc_auc_score(y_valid, scores)\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "# Create and test model\n",
    "mod = linear_model.LogisticRegression(penalty='l2', C=1, class_weight='balanced', solver='saga', max_iter=250)\n",
    "mod.fit(x_train, y_train)\n",
    "scores1 = mod.decision_function(x_train)\n",
    "new_results1 = {index: score for index, score in enumerate(scores1)}     \n",
    "sorted_items1 = sorted(new_results1.items(), key=lambda x: x[1], reverse=True)\n",
    "train_pred = np.zeros(len(x_train))\n",
    "for i in sorted_items1[:int(len(x_train)//2) + 1]:\n",
    "    train_pred[i[0]] = 1\n",
    "tn, tp, fn, fp = 0,0,0,0\n",
    "for guess, actual in zip(train_pred, y_train):\n",
    "    if guess == actual:\n",
    "        if guess == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    else:\n",
    "        if guess == 0:\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "print(\"Training Info: TP \", tp, \" TN \", tn, \" FP \", fp, \" FN \", fn)\n",
    "\n",
    "scores = mod.decision_function(x_valid)\n",
    "new_results = {index: score for index, score in enumerate(scores)}     \n",
    "sorted_items = sorted(new_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pred = np.zeros(len(x_valid))\n",
    "if len(x_valid) % 2 == 1:\n",
    "    for i in sorted_items[:int(10 * len(x_valid)//100) + 1]:\n",
    "        pred[i[0]] = 1\n",
    "else:\n",
    "    for i in sorted_items[:int(10 * len(x_valid)//100)]:\n",
    "        pred[i[0]] = 1\n",
    "\n",
    "curr_counter = 0\n",
    "all_pos = 0\n",
    "first_one = 0\n",
    "last_one = 0\n",
    "got_one = False\n",
    "got_all = 0\n",
    "while got_one < sum(y_valid) and curr_counter < len(sorted_items):\n",
    "    if y_valid[sorted_items[curr_counter][0]] == 1:\n",
    "        got_all += 1\n",
    "        if got_all == sum(y_valid):\n",
    "            last_one = curr_counter\n",
    "        all_pos += curr_counter\n",
    "        if got_one == False:\n",
    "            got_one = True \n",
    "            first_one = curr_counter\n",
    "    curr_counter += 1\n",
    "get_metric(y_valid, pred, mod.predict_proba(x_valid)[:,1])\n",
    "print(\"First spoiler position: \", first_one)\n",
    "print(\"Last spoiler position: \", last_one)\n",
    "print(\"Average spoiler position: \", all_pos / sum(y_valid))\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    pred = (scores >= threshold).astype(int)\n",
    "    current_f1 = f1_score(y_valid, pred)\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Best threshold for F1: {best_threshold}, F1: {best_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
