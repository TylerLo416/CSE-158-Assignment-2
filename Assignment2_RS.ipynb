{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91bf911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To upload to github, all changes you make to a clone of this repo / notebook \\nshould be stored somewhere and you can just push in a terminal or github desktop'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To upload to github, all changes you make to a clone of this repo / notebook \n",
    "should be stored somewhere and you can just push in a terminal or github desktop'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12a3bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything here is made for the bag of words model he showed in Tuesday Nov 19 lecture \\n- feel free to change anything, make your own model here or in a different ipynb\\n\\nEssentially, the model takes all review data, splits it up into truncated words, \\nand then makes a model using linear_model.Ridge that defines how much of an increase or decrease a word has\\non the predicted outcome\\n\\nnWords: # of words that the model takes into account to rate a book (currently 2000)\\n\\nTODO: use n-grams\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Everything here is made for the bag of words model he showed in Tuesday Nov 19 lecture \n",
    "- feel free to change anything, make your own model here or in a different ipynb\n",
    "\n",
    "Essentially, the model takes all review data, splits it up into truncated words, \n",
    "and then makes a model using linear_model.Ridge that defines how much of an increase or decrease a word has\n",
    "on the predicted outcome\n",
    "\n",
    "nWords: # of words that the model takes into account to rate a book (currently 2000)\n",
    "\n",
    "TODO: use n-grams\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7c6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1378033it [00:34, 39675.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '8842281e1d1347389f2ab93d60773d4d', 'timestamp': '2017-08-30', 'review_sentences': [[0, 'This is a special book.'], [0, 'It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind.'], [0, 'This is what I love about good science fiction - it pushes your thinking about where things can go.'], [0, \"It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I've read.\"], [0, 'For instance the intermixing of Chinese revolutionary history - how they kept accusing people of being \"reactionaries\", etc.'], [0, 'It is a book about science, and aliens.'], [0, 'The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell.'], [1, 'Though when it got to folding protons into 8 dimensions I think he was just making stuff up - interesting to think about though.'], [1, 'But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned?'], [1, 'That part of the book was a bit dark - I would like to think human reaction to discovering alien civilization that is hostile would be more like Enders Game where we would band together.'], [1, 'I did like how the book unveiled the Trisolaran culture through the game.'], [1, \"It was a smart way to build empathy with them and also understand what they've gone through across so many centuries.\"], [1, 'And who know a 3 body problem was an unsolvable math problem?'], [1, \"But I still don't get who made the game - maybe that will come in the next book.\"], [1, 'I loved this quote:'], [1, '\"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists?'], [1, 'How many neutrons and electrons?'], [1, 'Probably no fewer than a hundred million.'], [1, 'Every collision was probably the end of the civilizations and intelligences in a microcosmos.'], [1, 'In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons.'], [1, 'Also, a high-energy cosmic ray entering the atmosphere may destroy thousands of such miniature universes....\"']], 'rating': 5, 'has_spoiler': True, 'book_id': '18245960', 'review_id': 'dfdbb7b0eb5a7e4c26d59a937e2e5feb'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Path to the .json.gz file\n",
    "file_path = 'goodreads_reviews_spoiler.json.gz'\n",
    "\n",
    "# Open and read the file line by line\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    data = []\n",
    "    for line in tqdm(f):\n",
    "        # Parse each line as a separate JSON object\n",
    "        try:\n",
    "            review = json.loads(line)\n",
    "            data.append(review)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {e}\")\n",
    "\n",
    "# Example: Print the first parsed review\n",
    "if data:\n",
    "    print(data[0])\n",
    "else:\n",
    "    print(\"No data was parsed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7e3498-43aa-4b53-9bc2-57d29536a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd41fa37-a4c6-45ed-a839-e7719fc834c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1378033/1378033 [00:01<00:00, 712078.87it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for data_point in tqdm(data):\n",
    "    user_id = data_point['user_id']\n",
    "    book_id = data_point['book_id']\n",
    "    has_spoiler = 1 if data_point['has_spoiler'] else 0\n",
    "    dataset.append([user_id, book_id, has_spoiler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be45f584-a213-4151-ba4f-095d6139c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "length = len(dataset)\n",
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    random.shuffle(dataset)\n",
    "    \n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "    \n",
    "    train_data = dataset[:split_index]\n",
    "    test_data = dataset[split_index:]\n",
    "    \n",
    "    return train_data, test_data\n",
    "trainset, testset = split_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb775ac5-0482-45c1-be56-20224161025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fae84b8feeb9b3c6c2235d2570d1921b', '7802254', 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "755862ab-0249-4cc8-97ad-48b37e16632c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1102426/1102426 [00:03<00:00, 343810.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "entriesPerUser = defaultdict(list)\n",
    "entriesPerItem = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "for u,b,h in tqdm(trainset):\n",
    "    if h == 1:\n",
    "        entriesPerUser[u].append((b,h))\n",
    "        entriesPerItem[b].append((u,h))\n",
    "        usersPerItem[b].add(u)\n",
    "        itemsPerUser[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bc33965-82b6-4bea-905d-de5c41082a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(predictions, trueLabels):\n",
    "    diff_arr = numpy.array(predictions) - numpy.array(trueLabels)\n",
    "    correct_preds = 0\n",
    "    for i in diff_arr:\n",
    "        if i == 0:\n",
    "            correct_preds += 1\n",
    "    return correct_preds / len(trueLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248228b6-9a41-4a1a-968b-4eeff120a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1e82d0-f6bb-4643-af7f-1bb63e2a201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JaccardItems(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return 0\n",
    "    books_user_has_read = itemsPerUser[user]\n",
    "    users_who_read_item = usersPerItem[item]\n",
    "    max_jaccard = 0\n",
    "    for book in books_user_has_read:\n",
    "        if item != book:\n",
    "            users_who_read_book = usersPerItem[book]\n",
    "            jaccard_sim = Jaccard(users_who_read_book, users_who_read_item)\n",
    "            max_jaccard = max(max_jaccard, jaccard_sim)\n",
    "    return max_jaccard\n",
    "\n",
    "def JaccardUsers(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return 0\n",
    "    books_user_has_read = itemsPerUser[user]\n",
    "    users_who_read_item = usersPerItem[item]\n",
    "    max_jaccard = 0\n",
    "    for reader in users_who_read_item:\n",
    "        if user != reader:\n",
    "            items_reader_has_read = itemsPerUser[reader]\n",
    "            jaccard_sim = Jaccard(items_reader_has_read, books_user_has_read)\n",
    "            max_jaccard = max(max_jaccard, jaccard_sim)         \n",
    "    return max_jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2c8f915-0c14-4a87-a58e-64c98e8edf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(s1, s2):\n",
    "    vec1 = Counter(s1)\n",
    "    vec2 = Counter(s2)\n",
    "\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    dot_product = sum(vec1[item] * vec2[item] for item in intersection)\n",
    "\n",
    "    magnitude1 = math.sqrt(sum(count ** 2 for count in vec1.values()))\n",
    "    magnitude2 = math.sqrt(sum(count ** 2 for count in vec2.values()))\n",
    "\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "\n",
    "    return dot_product / (magnitude1 * magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73894913-ba68-4246-82f5-20e28ce186b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineItems(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return 0\n",
    "    books_user_has_read = itemsPerUser[user]\n",
    "    users_who_read_item = usersPerItem[item]\n",
    "    max_cosine = 0\n",
    "    for book in books_user_has_read:\n",
    "        if item != book:\n",
    "            users_who_read_book = usersPerItem[book]\n",
    "            cosine_sim = Cosine(users_who_read_book, users_who_read_item)\n",
    "            max_cosine = max(max_cosine, cosine_sim)\n",
    "    return max_cosine\n",
    "\n",
    "def CosineUsers(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return 0\n",
    "    books_user_has_read = itemsPerUser[user]\n",
    "    users_who_read_item = usersPerItem[item]\n",
    "    max_cosine = 0\n",
    "    for reader in users_who_read_item:\n",
    "        if user != reader:\n",
    "            items_reader_has_read = itemsPerUser[reader]\n",
    "            cosine_sim = Cosine(items_reader_has_read, books_user_has_read)\n",
    "            max_cosine = max(max_cosine, cosine_sim)         \n",
    "    return max_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33e8cbd0-f02a-4a0a-b922-610cbfdd6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def Pearson(s1, s2):\n",
    "    vec1 = Counter(s1)\n",
    "    vec2 = Counter(s2)\n",
    "\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    if not intersection:\n",
    "        return 0 \n",
    "\n",
    "    mean1 = sum(vec1[item] for item in intersection) / len(intersection)\n",
    "    mean2 = sum(vec2[item] for item in intersection) / len(intersection)\n",
    "\n",
    "    numer = sum((vec1[item] - mean1) * (vec2[item] - mean2) for item in intersection)\n",
    "    denom1 = sum((vec1[item] - mean1) ** 2 for item in intersection)\n",
    "    denom2 = sum((vec2[item] - mean2) ** 2 for item in intersection)\n",
    "\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f54634-5c7a-4b64-ac64-c3bfe1295791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PearsonItems(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return 0\n",
    "    books_user_has_read = itemsPerUser[user]\n",
    "    users_who_read_item = usersPerItem[item]\n",
    "    max_pearson = 0\n",
    "    for book in books_user_has_read:\n",
    "        if item != book:\n",
    "            users_who_read_book = usersPerItem[book]\n",
    "            pearson_sim = Pearson(users_who_read_book, users_who_read_item)\n",
    "            max_pearson = max(max_pearson, pearson_sim)\n",
    "    return max_pearson\n",
    "\n",
    "def PearsonUsers(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return 0\n",
    "    books_user_has_read = itemsPerUser[user]\n",
    "    users_who_read_item = usersPerItem[item]\n",
    "    max_pearson = 0\n",
    "    for reader in users_who_read_item:\n",
    "        if user != reader:\n",
    "            items_reader_has_read = itemsPerUser[reader]\n",
    "            pearson_sim = Pearson(items_reader_has_read, books_user_has_read)\n",
    "            max_pearson = max(max_pearson, pearson_sim)         \n",
    "    return max_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00a9047b-898d-4ec7-8162-61bb071a5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(u, b, h):\n",
    "    return [1] + [JaccardItems(u, b), JaccardUsers(u, b)] + [CosineItems(u, b), CosineUsers(u, b)] + [PearsonItems(u, b), PearsonUsers(u, b)]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a572ea98-1a0d-48cf-98f8-c3a8b7906c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 1102426/1102426 [05:26<00:00, 3381.33it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = []\n",
    "for u, b, h in tqdm(trainset):\n",
    "    Xtrain.append(feat(u, b, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1db43515-bfe1-472e-927a-a84b1d19ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1102426/1102426 [00:04<00:00, 246976.72it/s]\n",
      "100%|█████████████████████████████████| 275607/275607 [01:17<00:00, 3534.28it/s]\n",
      "100%|███████████████████████████████| 275607/275607 [00:01<00:00, 262735.10it/s]\n"
     ]
    }
   ],
   "source": [
    "ytrain = [r for _, _, r in tqdm(trainset)]\n",
    "Xtest = [feat(u, b, r) for u, b, r in tqdm(testset)]\n",
    "ytest = [r for _, _, r in tqdm(testset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "16d8725f-5be7-42b6-89f1-e191f8552748",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "for u, b, h in testset:\n",
    "    true_labels.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2291b2aa-244c-4079-bcaa-3b10ae9d7901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model C = 1000\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 100\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 10\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 1\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 0.1\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 0.01\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 0.001\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 0.0001\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n",
      "Model C = 1e-05\n",
      "0.9349109420297743\n",
      "FP: 0\n",
      "FN: 17939\n",
      "TP: 0\n",
      "TN: 257668\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_arr = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for c in C_arr:\n",
    "    print(\"Model C = \" + str(c))\n",
    "    mod = linear_model.LogisticRegression(class_weight='balanced', C=c)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    test_pred = (mod.predict_proba(Xtest)[:, 1] >= 1).astype(int)\n",
    "    print(calcAccuracy(test_pred, true_labels))\n",
    "    diff_arr = numpy.array(test_pred) - numpy.array(true_labels)\n",
    "    sum_arr = numpy.array(test_pred) + numpy.array(true_labels)\n",
    "    FP, FN = 0, 0\n",
    "    TP, TN = 0, 0\n",
    "    for i in diff_arr:\n",
    "        if i == 1:\n",
    "            FP += 1\n",
    "        if i == -1:\n",
    "            FN += 1\n",
    "    for i in sum_arr:\n",
    "        if i==0:\n",
    "            TN += 1\n",
    "        if i == 2:\n",
    "            TP += 1\n",
    "    print(\"FP: \" + str(FP))\n",
    "    print(\"FN: \" + str(FN))\n",
    "    print(\"TP: \" + str(TP))\n",
    "    print(\"TN: \" + str(TN))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "289b5909-40c7-471e-991b-0d4c59e2e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1000, Accuracy: 0.9270664388059809\n",
      "C = 100, Accuracy: 0.9270664388059809\n",
      "C = 10, Accuracy: 0.9270664388059809\n",
      "C = 1, Accuracy: 0.9270628104511134\n",
      "C = 0.1, Accuracy: 0.9271244924838629\n",
      "C = 0.01, Accuracy: 0.9275925502617858\n",
      "C = 0.001, Accuracy: 0.9288733595300555\n",
      "C = 0.0001, Accuracy: 0.9321098520719721\n",
      "C = 1e-05, Accuracy: 0.9349109420297743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "C_arr = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for c in C_arr:\n",
    "    model = LinearSVC(random_state=42, max_iter=100000, C=c)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    y_pred = model.predict(Xtest)\n",
    "    accuracy = calcAccuracy(y_pred, true_labels)\n",
    "    print(\"C = \" + str(c) + \", \" + \"Accuracy: \" + str(accuracy))\n",
    "    # diff_arr = numpy.array(test_pred) - numpy.array(true_labels)\n",
    "    # sum_arr = numpy.array(test_pred) + numpy.array(true_labels)\n",
    "    # FP, FN = 0, 0\n",
    "    # TP, TN = 0, 0\n",
    "    # for i in diff_arr:\n",
    "    #     if i == 1:\n",
    "    #         FP += 1\n",
    "    #     if i == -1:\n",
    "    #         FN += 1\n",
    "    # for i in sum_arr:\n",
    "    #     if i==0:\n",
    "    #         TN += 1\n",
    "    #     if i == 2:\n",
    "    #         TP += 1\n",
    "    # print(\"FP: \" + str(FP))\n",
    "    # print(\"FN: \" + str(FN))\n",
    "    # print(\"TP: \" + str(TP))\n",
    "    # print(\"TN: \" + str(TN))\n",
    "    # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9103579-ce22-4c04-b271-20bd54ef278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under-Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c8aea9b-9611-43e5-8670-37332544e101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143948"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoiler_reviews = [entry for entry in trainset if entry[2] == 1]\n",
    "non_spoiler_reviews = [entry for entry in trainset if entry[2] == 0]\n",
    "\n",
    "sampled_non_spoiler_reviews = random.sample(non_spoiler_reviews, len(spoiler_reviews))\n",
    "balanced_trainset = spoiler_reviews + sampled_non_spoiler_reviews\n",
    "len(balanced_trainset)\n",
    "# Not feasible because our train set ends up being smaller than the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a665cf4-ef38-4257-b841-cdac89bf543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cbf7b7-0af8-4164-8ca2-24c11a92b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4b99462-97bd-4454-9322-9eccab2f7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = np.array(trainset)\n",
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n",
    "\n",
    "user_encoded = user_encoder.fit_transform(trainset[:, 0])\n",
    "book_encoded = book_encoder.fit_transform(trainset[:, 1])\n",
    "X = np.column_stack((user_encoded, book_encoded))\n",
    "y = trainset[:, 2].astype(int)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "user_resampled = user_encoder.inverse_transform(X_resampled[:, 0].astype(int))\n",
    "book_resampled = book_encoder.inverse_transform(X_resampled[:, 1].astype(int))\n",
    "\n",
    "resampled_trainset = np.column_stack((user_resampled, book_resampled, y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71c8b827-f0d6-4b41-bede-c7c4b8f3ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 2061832/2061832 [00:02<00:00, 974607.56it/s]\n"
     ]
    }
   ],
   "source": [
    "resampled_trainset = [[i[0], i[1], 1 if i[2] == \"1\" else 0] for i in tqdm(resampled_trainset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67f35b2a-4f80-4c73-adb2-5f301645e17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061832"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_trainset[0]\n",
    "len(resampled_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e392ca3-6ca5-411f-93ac-33bcdeb2083f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030916"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(resampled_trainset)\n",
    "resampled_trainset = resampled_trainset[:len(resampled_trainset) // 2]\n",
    "# resampled_trainset[0]\n",
    "len(resampled_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b902efb-5b04-4d02-b3b1-5b951c8ec5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1030916/1030916 [00:01<00:00, 663721.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "entriesPerUser = defaultdict(list)\n",
    "entriesPerItem = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "for u,b,h in tqdm(resampled_trainset):\n",
    "    if h == 1:\n",
    "        entriesPerUser[u].append((b,h))\n",
    "        entriesPerItem[b].append((u,h))\n",
    "        usersPerItem[b].add(u)\n",
    "        itemsPerUser[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9d6fa13-dba3-44d8-9b22-76e2ac98b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 1030916/1030916 [31:04<00:00, 552.99it/s]\n",
      "100%|████████████████████████████| 1030916/1030916 [00:00<00:00, 1513688.95it/s]\n",
      "100%|██████████████████████████████████| 275607/275607 [08:16<00:00, 555.37it/s]\n",
      "100%|███████████████████████████████| 275607/275607 [00:01<00:00, 216443.14it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = []\n",
    "for u, b, h in tqdm(resampled_trainset):\n",
    "    Xtrain.append(feat(u, b, h))\n",
    "\n",
    "ytrain = [r for _, _, r in tqdm(resampled_trainset)]\n",
    "\n",
    "Xtest = [feat(u, b, r) for u, b, r in tqdm(testset)]\n",
    "\n",
    "ytest = [r for _, _, r in tqdm(testset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32c94d8f-47da-4d6d-8fc1-707f5937daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "for u, b, h in testset:\n",
    "    true_labels.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbee43ab-f066-42c2-ac9c-d299c64af574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model C = 1000\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 100\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 10\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 1\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.1\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.01\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.001\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.0001\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 1e-05\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_arr = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for c in C_arr:\n",
    "    print(\"Model C = \" + str(c))\n",
    "    mod = linear_model.LogisticRegression(class_weight='balanced', C=c)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    test_pred = (mod.predict_proba(Xtest)[:, 1] >= 1).astype(int)\n",
    "    print(calcAccuracy(test_pred, true_labels))\n",
    "    diff_arr = numpy.array(test_pred) - numpy.array(true_labels)\n",
    "    sum_arr = numpy.array(test_pred) + numpy.array(true_labels)\n",
    "    FP, FN = 0, 0\n",
    "    TP, TN = 0, 0\n",
    "    for i in diff_arr:\n",
    "        if i == 1:\n",
    "            FP += 1\n",
    "        if i == -1:\n",
    "            FN += 1\n",
    "    for i in sum_arr:\n",
    "        if i==0:\n",
    "            TN += 1\n",
    "        if i == 2:\n",
    "            TP += 1\n",
    "    print(\"FP: \" + str(FP))\n",
    "    print(\"FN: \" + str(FN))\n",
    "    print(\"TP: \" + str(TP))\n",
    "    print(\"TN: \" + str(TN))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53102998-0fd6-4426-9d3d-1e2cb10df311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1000, Accuracy: 0.8905434187085234\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 100, Accuracy: 0.8905361619987882\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 10, Accuracy: 0.8905724455474643\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 1, Accuracy: 0.8906123574510081\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 0.1, Accuracy: 0.889574647958869\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 0.01, Accuracy: 0.8872488724887249\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 0.001, Accuracy: 0.8818680222200452\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 0.0001, Accuracy: 0.873403070313889\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "C = 1e-05, Accuracy: 0.8610666637639828\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "C_arr = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for c in C_arr:\n",
    "    model = LinearSVC(random_state=42, max_iter=100000, C=c)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    y_pred = model.predict(Xtest)\n",
    "    accuracy = calcAccuracy(y_pred, true_labels)\n",
    "    print(\"C = \" + str(c) + \", \" + \"Accuracy: \" + str(accuracy))\n",
    "    diff_arr = numpy.array(test_pred) - numpy.array(true_labels)\n",
    "    sum_arr = numpy.array(test_pred) + numpy.array(true_labels)\n",
    "    FP, FN = 0, 0\n",
    "    TP, TN = 0, 0\n",
    "    for i in diff_arr:\n",
    "        if i == 1:\n",
    "            FP += 1\n",
    "        if i == -1:\n",
    "            FN += 1\n",
    "    for i in sum_arr:\n",
    "        if i==0:\n",
    "            TN += 1\n",
    "        if i == 2:\n",
    "            TP += 1\n",
    "    print(\"FP: \" + str(FP))\n",
    "    print(\"FN: \" + str(FN))\n",
    "    print(\"TP: \" + str(TP))\n",
    "    print(\"TN: \" + str(TN))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d45c4ac3-ec91-45eb-bf54-f38744d9d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed5bdddf-b7b3-4056-9996-dfd46dec4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, stratify=[entry[2] for entry in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8879363a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275607"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "713f4b9d-6ec5-4b25-aaca-81ce7bf05c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1102426/1102426 [00:01<00:00, 724579.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "entriesPerUser = defaultdict(list)\n",
    "entriesPerItem = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "for u,b,h in tqdm(trainset):\n",
    "    if h == 1:\n",
    "        entriesPerUser[u].append((b,h))\n",
    "        entriesPerItem[b].append((u,h))\n",
    "        usersPerItem[b].add(u)\n",
    "        itemsPerUser[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01c37592-e996-46eb-beb9-b85b919e22be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 1102426/1102426 [00:20<00:00, 52577.63it/s]\n",
      "100%|█████████████████████████████| 1102426/1102426 [00:01<00:00, 778070.66it/s]\n",
      "100%|███████████████████████████████| 275607/275607 [00:01<00:00, 180005.29it/s]\n",
      "100%|██████████████████████████████| 275607/275607 [00:00<00:00, 1518564.04it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = []\n",
    "for u, b, h in tqdm(trainset):\n",
    "    Xtrain.append(feat(u, b, h))\n",
    "\n",
    "ytrain = [r for _, _, r in tqdm(trainset)]\n",
    "\n",
    "Xtest = [feat(u, b, r) for u, b, r in tqdm(testset)]\n",
    "\n",
    "ytest = [r for _, _, r in tqdm(testset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1afbe878-33ac-4fe8-a621-48fe6f49a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model C = 1000\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 100\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 10\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 1\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.1\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.01\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.001\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 0.0001\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n",
      "Model C = 1e-05\n",
      "0.934265094863338\n",
      "FP: 0\n",
      "FN: 18117\n",
      "TP: 0\n",
      "TN: 257490\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_arr = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "for c in C_arr:\n",
    "    print(\"Model C = \" + str(c))\n",
    "    mod = linear_model.LogisticRegression(class_weight='balanced', C=c)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    test_pred = (mod.predict_proba(Xtest)[:, 1] >= 1).astype(int)\n",
    "    print(calcAccuracy(test_pred, true_labels))\n",
    "    diff_arr = numpy.array(test_pred) - numpy.array(true_labels)\n",
    "    sum_arr = numpy.array(test_pred) + numpy.array(true_labels)\n",
    "    FP, FN = 0, 0\n",
    "    TP, TN = 0, 0\n",
    "    for i in diff_arr:\n",
    "        if i == 1:\n",
    "            FP += 1\n",
    "        if i == -1:\n",
    "            FN += 1\n",
    "    for i in sum_arr:\n",
    "        if i==0:\n",
    "            TN += 1\n",
    "        if i == 2:\n",
    "            TP += 1\n",
    "    print(\"FP: \" + str(FP))\n",
    "    print(\"FN: \" + str(FN))\n",
    "    print(\"TP: \" + str(TP))\n",
    "    print(\"TN: \" + str(TN))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307be46e-7261-4651-8540-2e6a01303f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
