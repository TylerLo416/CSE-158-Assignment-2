{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3912d684-3589-4b73-a040-1a3ffd65906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 03:11:25.380239: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 03:11:25.423468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 03:11:25.423503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 03:11:25.424741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 03:11:25.432828: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf12170-1905-4e0b-adf1-21e28008a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '8842281e1d1347389f2ab93d60773d4d', 'timestamp': '2017-08-30', 'review_sentences': [[0, 'This is a special book.'], [0, 'It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind.'], [0, 'This is what I love about good science fiction - it pushes your thinking about where things can go.'], [0, \"It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I've read.\"], [0, 'For instance the intermixing of Chinese revolutionary history - how they kept accusing people of being \"reactionaries\", etc.'], [0, 'It is a book about science, and aliens.'], [0, 'The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell.'], [1, 'Though when it got to folding protons into 8 dimensions I think he was just making stuff up - interesting to think about though.'], [1, 'But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned?'], [1, 'That part of the book was a bit dark - I would like to think human reaction to discovering alien civilization that is hostile would be more like Enders Game where we would band together.'], [1, 'I did like how the book unveiled the Trisolaran culture through the game.'], [1, \"It was a smart way to build empathy with them and also understand what they've gone through across so many centuries.\"], [1, 'And who know a 3 body problem was an unsolvable math problem?'], [1, \"But I still don't get who made the game - maybe that will come in the next book.\"], [1, 'I loved this quote:'], [1, '\"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists?'], [1, 'How many neutrons and electrons?'], [1, 'Probably no fewer than a hundred million.'], [1, 'Every collision was probably the end of the civilizations and intelligences in a microcosmos.'], [1, 'In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons.'], [1, 'Also, a high-energy cosmic ray entering the atmosphere may destroy thousands of such miniature universes....\"']], 'rating': 5, 'has_spoiler': True, 'book_id': '18245960', 'review_id': 'dfdbb7b0eb5a7e4c26d59a937e2e5feb'}\n"
     ]
    }
   ],
   "source": [
    "# Path to the .json.gz file\n",
    "file_path = 'goodreads_reviews_spoiler.json.gz'\n",
    "ct = 0\n",
    "# Open and read the file line by line\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        # Parse each line as a separate JSON object\n",
    "        try:\n",
    "            ct += 1\n",
    "            review = json.loads(line)\n",
    "            #review.pop('has_spoiler', None)\n",
    "            data.append(review)\n",
    "            if ct == 12000:\n",
    "                break\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {e}\")\n",
    "\n",
    "# Example: Print the first parsed review\n",
    "if data:\n",
    "    print(data[0])\n",
    "else:\n",
    "    print(\"No data was parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eb908a-fd05-4513-ab5a-eceaac925134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '8842281e1d1347389f2ab93d60773d4d',\n",
       " 'timestamp': '2017-08-30',\n",
       " 'review_sentences': [[0, 'It is a book about science, and aliens.'],\n",
       "  [0, 'This is a special book.'],\n",
       "  [1,\n",
       "   \"It was a smart way to build empathy with them and also understand what they've gone through across so many centuries.\"],\n",
       "  [1,\n",
       "   '\"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists?']],\n",
       " 'rating': 5,\n",
       " 'has_spoiler': True,\n",
       " 'book_id': '18245960',\n",
       " 'review_id': 'dfdbb7b0eb5a7e4c26d59a937e2e5feb'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 10000\n",
    "test_size = 1000\n",
    "\n",
    "\n",
    "ratingsTrain = []\n",
    "for i in data[:train_size]:\n",
    "    if i['has_spoiler']:\n",
    "        copy_to_upload = i\n",
    "        non_spoilers = [sentence for sentence in i['review_sentences'] if sentence[0] == 0]\n",
    "        spoilers = [sentence for sentence in i['review_sentences'] if sentence[0] == 1]\n",
    "        \n",
    "        selected_non_spoilers = []\n",
    "        selected_spoilers = []\n",
    "        if len(non_spoilers) > 0:\n",
    "            selected_non_spoilers = random.choices(non_spoilers, k=2)\n",
    "        if len(spoilers) > 0:\n",
    "            selected_spoilers = random.choices(spoilers, k=2)\n",
    "            \n",
    "        new_sentences = selected_non_spoilers + selected_spoilers\n",
    "        copy_to_upload['review_sentences'] = new_sentences\n",
    "\n",
    "        ratingsTrain.append(copy_to_upload)\n",
    "\n",
    "ratingsTest = data[train_size:train_size + test_size]\n",
    "ratingsTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8bacbf7-f2dc-43cd-9ebd-9188d1ae655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def get_bert_embedding(sentence):\n",
    "    \"\"\"Generate BERT embedding for a single sentence.\"\"\"\n",
    "    tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        # Use the [CLS] token's embedding as the sentence embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "for d in data:\n",
    "    usersPerItem[d['book_id']].add(d['user_id'])\n",
    "    itemsPerUser[d['user_id']].add(d['book_id'])\n",
    "    ratingsPerUser[d['user_id']].append(d['rating'])\n",
    "    ratingsPerItem[d['book_id']].append(d['rating'])\n",
    "    for i in d['review_sentences']:\n",
    "        reviewsPerItem[d['book_id']].append(i[0])\n",
    "        reviewsPerUser[d['user_id']].append(i[0])\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for d in data:\n",
    "    bookCount[d['book_id']] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "PopularityBooks = [x[-1] for x in mostPopular]\n",
    "\n",
    "mostPopularUsers = [[len(value), key] for key, value in itemsPerUser.items()]\n",
    "mostPopularUsers.sort()\n",
    "mostPopularUsers.reverse()\n",
    "PopularityUsers = [x[-1] for x in mostPopularUsers]\n",
    "\n",
    "userIDs, itemIDs = {}, {}\n",
    "for d in data:\n",
    "    if d['user_id'] not in userIDs: userIDs[d['user_id']] = len(userIDs)\n",
    "    if d['book_id'] not in itemIDs: itemIDs[d['book_id']] = len(itemIDs)\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "Xui = scipy.sparse.lil_matrix((nUsers, nItems))\n",
    "for d in data:\n",
    "    Xui[userIDs[d['user_id']], itemIDs[d['book_id']]] = 1 \n",
    "\n",
    "Xui_csr = scipy.sparse.csr_matrix(Xui)\n",
    "\n",
    "book_popularity = np.sum(Xui_csr, axis=0).A1\n",
    "books_read_by_user = Xui_csr.sum(axis=1).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06fb2490-d495-4a59-84a1-2581c4566f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_user_pop = sum(book_popularity) / len(book_popularity)\n",
    "avg_user_freq = sum(books_read_by_user) / len(books_read_by_user)\n",
    "avg_pop_by_freq = avg_user_pop * avg_user_freq\n",
    "avg_book_rank = len(PopularityBooks) / 2\n",
    "avg_user_rank = len(PopularityUsers) / 2\n",
    "#avg_ct_book_spoilers = 0.179359243697479\n",
    "spoiler_flat = [sum(sublist) for sublist in reviewsPerItem.values()]\n",
    "avg_ct_book_spoilers = sum(spoiler_flat) / len(spoiler_flat) if spoiler_flat else 0\n",
    "spoiler_flat_2 = [sum(sublist) for sublist in reviewsPerUser.values()]\n",
    "#avg_ct_user_spoilers = 10.841269841269842\n",
    "avg_ct_user_spoilers = sum(spoiler_flat_2) / len(spoiler_flat_2) if spoiler_flat_2 else 0\n",
    "flattened_1 = [item for sublist in ratingsPerItem.values() for item in sublist]\n",
    "ovr_avg_rating_item =  sum(flattened_1) / len(flattened_1) if flattened_1 else 0\n",
    "flattened_2 = [item for sublist in ratingsPerUser.values() for item in sublist]\n",
    "ovr_avg_rating_user = sum(flattened_2) / len(flattened_2) if flattened_2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4c1fd-4fac-4707-9449-f10af0adff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = set(userIDs.keys())\n",
    "books = set(itemIDs.keys())\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def create_vector(review):\n",
    "    global users, books, avg_ct_book_spoilers, avg_ct_user_spoilers, ovr_avg_rating_item, ovr_avg_rating_user\n",
    "\n",
    "    u = review['user_id']\n",
    "    b = review['book_id']\n",
    "    timestamp = review['timestamp']\n",
    "    sentence = review['BERT_data']\n",
    "    rating = review['rating']\n",
    "    # Default feature values\n",
    "    book_in = b in books\n",
    "    user_in = u in users\n",
    "     if len(sentence) == 0:\n",
    "        sentence = np.zeros(768) # Placeholder for BERT embedding\n",
    "    temporal_feature = 0           # Placeholder for temporal information\n",
    "    user_rating = rating if rating is not None else 0  # Use given rating\n",
    "\n",
    "    # Book and user interaction features\n",
    "    if book_in and user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = book_pop * user_freq\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        user_rank = PopularityUsers.index(u)\n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        avg_rating_user = ratingsPerUser[u]\n",
    "        avg_rating_user = sum(avg_rating_user) / len(avg_rating_user)\n",
    "    elif not user_in and not book_in:\n",
    "        book_pop = len(books)\n",
    "        user_freq = 0\n",
    "        pop_by_freq = 0\n",
    "        book_rank = len(books)\n",
    "        user_rank = len(users)\n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        avg_rating_user = ovr_avg_rating_user\n",
    "    elif not user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = 0\n",
    "        pop_by_freq = book_pop\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        user_rank = len(PopularityUsers)\n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        avg_rating_user = ovr_avg_rating_user\n",
    "    else:\n",
    "        book_pop = 0\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = user_freq\n",
    "        book_rank = len(PopularityBooks)\n",
    "        user_rank = PopularityUsers.index(u)\n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        avg_rating_user = ratingsPerUser[u]\n",
    "        avg_rating_user = sum(avg_rating_user) / len(avg_rating_user)\n",
    "\n",
    "    # Add BERT embedding for the sentence\n",
    "    bert_embedding = get_bert_embedding(sentence)  # Assuming a defined function\n",
    "\n",
    "    # Add temporal feature based on timestamp\n",
    "    try:\n",
    "        review_date = datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "        current_date = datetime.now()\n",
    "        temporal_feature = (current_date - review_date).days  # Time in days\n",
    "    except ValueError:\n",
    "        temporal_feature = 0  # Default value if timestamp parsing fails\n",
    "\n",
    "    # Combine features\n",
    "    vals = [\n",
    "        1,  # Bias term\n",
    "        book_pop,          # Book popularity\n",
    "        pop_by_freq,       # Popularity scaled by user frequency\n",
    "        user_rank,         # User ranking\n",
    "        user_rating,       # User's rating\n",
    "        temporal_feature,   # Temporal feature\n",
    "        ct_book_spoilers,\n",
    "        ct_user_spoilers,\n",
    "        avg_rating_item,\n",
    "        avg_rating_user\n",
    "    ]\n",
    "    \n",
    "    # Append BERT embeddings\n",
    "    vals.extend(sentence.tolist())\n",
    "    \n",
    "    return vals\n",
    "\n",
    "#TAKES A LONG TIME ~30-45 min for just 11k entries\n",
    "x_train = []\n",
    "y_train = []\n",
    "for d in ratingsTrain:\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    for sentence in d['review_sentences']:\n",
    "        bert_embedding = get_bert_embedding(sentence[1])\n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        x_train.append(filtered_data)\n",
    "        y_train.append(sentence[0])\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "for d in ratingsTrain:\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    for sentence in d['review_sentences']:\n",
    "        bert_embedding = get_bert_embedding(sentence[1])\n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        x_valid.append(filtered_data)\n",
    "        y_valid.append(sentence[0])\n",
    "        \n",
    "\n",
    "x_train = [create_vector(i) for i in x_train]\n",
    "x_valid = [create_vector(i) for i in x_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054c075-d2c7-4350-944a-079e8c90ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(y_true, pred, scores, scores2):\n",
    "    corr = 0\n",
    "    tn, tp, fn, fp = 0,0,0,0\n",
    "    for guess, actual in zip(pred, y_true):\n",
    "        if guess == actual:\n",
    "            corr += 1\n",
    "            if guess == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        else:\n",
    "            if guess == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    if tp + fp == 0:\n",
    "        precision = 0\n",
    "        print(\"precision error, tp + fp = 0\")\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "        print(\"recall error, tp + fn = 0\")\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    print(\"accuracy: \", corr / len(pred))\n",
    "    print(\"tp: \", tp, \"tn: \", tn, \"fp: \", fp, \"fn: \", fn)\n",
    "    # Calculate F1 Score\n",
    "    if precision + recall == 0:\n",
    "        print(\"F1 error, precision + recall = 0\")\n",
    "    else:\n",
    "        print(\"F1: \", 2 * (precision * recall) / (precision + recall))\n",
    "    #auc = roc_auc_score(y_valid, scores)\n",
    "    #print(f\"AUC: {auc}\")\n",
    "    auc = roc_auc_score(y_valid, scores2)\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "\n",
    "mod = linear_model.LogisticRegression(C=100, class_weight = 'balanced')\n",
    "mod.fit(x_train,y_train)\n",
    "scores = mod.decision_function(x_valid_new)\n",
    "new_results = {index: score for index, score in enumerate(scores)}     \n",
    "sorted_items = sorted(new_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pred = np.zeros(len(x_valid_new))\n",
    "if len(x_valid_new) % 2 == 1:\n",
    "    for i in sorted_items[:int(3 * len(x_valid_new)//100) + 1]:\n",
    "        pred[i[0]] = 1\n",
    "else:\n",
    "    for i in sorted_items[:int(3 * len(x_valid_new)//100)]:\n",
    "        pred[i[0]] = 1\n",
    "\n",
    "curr_counter = 0\n",
    "all_pos = 0\n",
    "first_one = 0\n",
    "last_one = 0\n",
    "got_one = False\n",
    "got_all = 0\n",
    "while got_one < sum(y_valid) and curr_counter < len(sorted_items):\n",
    "    if y_valid[sorted_items[curr_counter][0]] == 1:\n",
    "        got_all += 1\n",
    "        if got_all == sum(y_valid):\n",
    "            last_one = curr_counter\n",
    "        all_pos += curr_counter\n",
    "        if got_one == False:\n",
    "            got_one = True \n",
    "            first_one = curr_counter\n",
    "    curr_counter += 1\n",
    "    \n",
    "get_metric(y_valid, pred, scores, mod.predict_proba(x_valid_new)[:,1])\n",
    "print(\"First spoiler position: \", first_one)\n",
    "print(\"Last spoiler position: \", last_one)\n",
    "print(\"Average spoiler position: \", all_pos / sum(y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
