{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f78cef-23da-4ae7-84bf-be8d41074d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 23:29:53.522943: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-30 23:29:53.571710: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-30 23:29:53.571750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-30 23:29:53.572977: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-30 23:29:53.581270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f2a210-2be4-42e5-b8d0-383ddd5d2dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '8842281e1d1347389f2ab93d60773d4d', 'timestamp': '2017-08-30', 'review_sentences': [[0, 'This is a special book.'], [0, 'It started slow for about the first third, then in the middle third it started to get interesting, then the last third blew my mind.'], [0, 'This is what I love about good science fiction - it pushes your thinking about where things can go.'], [0, \"It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I've read.\"], [0, 'For instance the intermixing of Chinese revolutionary history - how they kept accusing people of being \"reactionaries\", etc.'], [0, 'It is a book about science, and aliens.'], [0, 'The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell.'], [1, 'Though when it got to folding protons into 8 dimensions I think he was just making stuff up - interesting to think about though.'], [1, 'But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned?'], [1, 'That part of the book was a bit dark - I would like to think human reaction to discovering alien civilization that is hostile would be more like Enders Game where we would band together.'], [1, 'I did like how the book unveiled the Trisolaran culture through the game.'], [1, \"It was a smart way to build empathy with them and also understand what they've gone through across so many centuries.\"], [1, 'And who know a 3 body problem was an unsolvable math problem?'], [1, \"But I still don't get who made the game - maybe that will come in the next book.\"], [1, 'I loved this quote:'], [1, '\"In the long history of scientific progress, how many protons have been smashed apart in accelerators by physicists?'], [1, 'How many neutrons and electrons?'], [1, 'Probably no fewer than a hundred million.'], [1, 'Every collision was probably the end of the civilizations and intelligences in a microcosmos.'], [1, 'In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons.'], [1, 'Also, a high-energy cosmic ray entering the atmosphere may destroy thousands of such miniature universes....\"']], 'rating': 5, 'has_spoiler': True, 'book_id': '18245960', 'review_id': 'dfdbb7b0eb5a7e4c26d59a937e2e5feb'}\n"
     ]
    }
   ],
   "source": [
    "# Path to the .json.gz file\n",
    "file_path = 'goodreads_reviews_spoiler.json.gz'\n",
    "ct = 0\n",
    "# Open and read the file line by line\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        # Parse each line as a separate JSON object\n",
    "        try:\n",
    "            ct += 1\n",
    "            review = json.loads(line)\n",
    "            #review.pop('has_spoiler', None)\n",
    "            data.append(review)\n",
    "            if ct == 12000:\n",
    "                break\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding line: {e}\")\n",
    "\n",
    "# Example: Print the first parsed review\n",
    "if data:\n",
    "    print(data[0])\n",
    "else:\n",
    "    print(\"No data was parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52fd288-ce60-469f-9a83-fbf51d89c0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '8842281e1d1347389f2ab93d60773d4d',\n",
       " 'timestamp': '2017-08-30',\n",
       " 'review_sentences': [[0,\n",
       "   'The science described in the book is impressive - its a book grounded in physics and pretty accurate as far as I could tell.'],\n",
       "  [0,\n",
       "   \"It is a 2015 Hugo winner, and translated from its original Chinese, which made it interesting in just a different way from most things I've read.\"],\n",
       "  [1,\n",
       "   'But what would happen if our SETI stations received a message - if we found someone was out there - and the person monitoring and answering the signal on our side was disillusioned?'],\n",
       "  [1,\n",
       "   'In fact, even in nature, the destruction of universes must be happening at every second--for example, through the decay of neutrons.']],\n",
       " 'rating': 5,\n",
       " 'has_spoiler': True,\n",
       " 'book_id': '18245960',\n",
       " 'review_id': 'dfdbb7b0eb5a7e4c26d59a937e2e5feb'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsTrain = []\n",
    "for i in data[:10000]:\n",
    "    if i['has_spoiler']:\n",
    "        copy_to_upload = i\n",
    "        non_spoilers = [sentence for sentence in i['review_sentences'] if sentence[0] == 0]\n",
    "        spoilers = [sentence for sentence in i['review_sentences'] if sentence[0] == 1]\n",
    "        \n",
    "        selected_non_spoilers = []\n",
    "        selected_spoilers = []\n",
    "        if len(non_spoilers) > 0:\n",
    "            selected_non_spoilers = random.choices(non_spoilers, k=2)\n",
    "        if len(spoilers) > 0:\n",
    "            selected_spoilers = random.choices(spoilers, k=2)\n",
    "            \n",
    "        new_sentences = selected_non_spoilers + selected_spoilers\n",
    "        copy_to_upload['review_sentences'] = new_sentences\n",
    "\n",
    "        ratingsTrain.append(copy_to_upload)\n",
    "\n",
    "ratingsTest = data[10000:11000]\n",
    "ratingsTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee9e1ca-64de-4873-be9a-f11db76357f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def get_bert_embedding(sentence):\n",
    "    \"\"\"Generate BERT embedding for a single sentence.\"\"\"\n",
    "    tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        # Use the [CLS] token's embedding as the sentence embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f21207f-8d0c-4aaa-964b-0f50fbe3142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "for d in data:\n",
    "    usersPerItem[d['book_id']].add(d['user_id'])\n",
    "    itemsPerUser[d['user_id']].add(d['book_id'])\n",
    "    ratingsPerUser[d['user_id']].append(d['rating'])\n",
    "    ratingsPerItem[d['book_id']].append(d['rating'])\n",
    "    for i in d['review_sentences']:\n",
    "        reviewsPerItem[d['book_id']].append(i[0])\n",
    "        reviewsPerUser[d['user_id']].append(i[0])\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for d in ratingsTrain:\n",
    "    bookCount[d['book_id']] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "PopularityBooks = [x[-1] for x in mostPopular]\n",
    "\n",
    "mostPopularUsers = [[len(value), key] for key, value in itemsPerUser.items()]\n",
    "mostPopularUsers.sort()\n",
    "mostPopularUsers.reverse()\n",
    "PopularityUsers = [x[-1] for x in mostPopularUsers]\n",
    "\n",
    "userIDs, itemIDs = {}, {}\n",
    "for d in ratingsTrain + ratingsTest:\n",
    "    if d['user_id'] not in userIDs: userIDs[d['user_id']] = len(userIDs)\n",
    "    if d['book_id'] not in itemIDs: itemIDs[d['book_id']] = len(itemIDs)\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "Xui = scipy.sparse.lil_matrix((nUsers, nItems))\n",
    "\n",
    "for d in ratingsTrain + ratingsTest:\n",
    "    Xui[userIDs[d['user_id']], itemIDs[d['book_id']]] = 1 \n",
    "\n",
    "Xui_csr = scipy.sparse.csr_matrix(Xui)\n",
    "\n",
    "book_popularity = np.sum(Xui_csr, axis=0).A1\n",
    "books_read_by_user = Xui_csr.sum(axis=1).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c808ca0f-507e-4044-b4c5-92b47a0a2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_user_pop = sum(book_popularity) / len(book_popularity)\n",
    "avg_user_freq = sum(books_read_by_user) / len(books_read_by_user)\n",
    "avg_pop_by_freq = avg_user_pop * avg_user_freq\n",
    "avg_book_rank = len(PopularityBooks) / 2\n",
    "avg_user_rank = len(PopularityUsers) / 2\n",
    "avg_ct_book_spoilers = 0.179359243697479\n",
    "avg_ct_user_spoilers = 10.841269841269842\n",
    "flattened_1 = [item for sublist in ratingsPerItem.values() for item in sublist]\n",
    "ovr_avg_rating_item =  sum(flattened_1) / len(flattened_1) if flattened_1 else 0\n",
    "flattened_2 = [item for sublist in ratingsPerUser.values() for item in sublist]\n",
    "ovr_avg_rating_user = sum(flattened_2) / len(flattened_2) if flattened_2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db23a4c4-ad54-4743-a91e-cab3595be845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n",
      "newer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_sentences\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhas_spoiler\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_sentences\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 115\u001b[0m     bert_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_bert_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_data\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m bert_embedding\n\u001b[1;32m    117\u001b[0m     x_valid\u001b[38;5;241m.\u001b[39mappend(filtered_data)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      8\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer(sentence, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Use the [CLS] token's embedding as the sentence embedding\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     cls_embedding \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:523\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[1;32m    516\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[0;32m--> 523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:465\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 465\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    467\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "users = set(userIDs.keys())\n",
    "books = set(itemIDs.keys())\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def create_vector(review):\n",
    "    global users, books, avg_ct_book_spoilers, avg_ct_user_spoilers, ovr_avg_rating_item, ovr_avg_rating_user\n",
    "\n",
    "    u = review['user_id']\n",
    "    b = review['book_id']\n",
    "    timestamp = review['timestamp']\n",
    "    sentence = review['BERT_data']\n",
    "    rating = review['rating']\n",
    "    # Default feature values\n",
    "    book_in = b in books\n",
    "    user_in = u in users\n",
    "    bert_embedding = np.zeros(768)  # Placeholder for BERT embedding\n",
    "    temporal_feature = 0           # Placeholder for temporal information\n",
    "    user_rating = rating if rating is not None else 0  # Use given rating\n",
    "\n",
    "    # Book and user interaction features\n",
    "    if book_in and user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = book_pop * user_freq\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        user_rank = PopularityUsers.index(u)\n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        avg_rating_user = ratingsPerUser[u]\n",
    "        avg_rating_user = sum(avg_rating_user) / len(avg_rating_user)\n",
    "    elif not user_in and not book_in:\n",
    "        book_pop = len(books)\n",
    "        user_freq = 0\n",
    "        pop_by_freq = 0\n",
    "        book_rank = len(books)\n",
    "        user_rank = len(users)\n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        avg_rating_user = ovr_avg_rating_user\n",
    "    elif not user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = 0\n",
    "        pop_by_freq = book_pop\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        user_rank = len(PopularityUsers)\n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        avg_rating_user = ovr_avg_rating_user\n",
    "    else:\n",
    "        book_pop = 0\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = user_freq\n",
    "        book_rank = len(PopularityBooks)\n",
    "        user_rank = PopularityUsers.index(u)\n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        avg_rating_user = ratingsPerUser[u]\n",
    "        avg_rating_user = sum(avg_rating_user) / len(avg_rating_user)\n",
    "\n",
    "    # Add BERT embedding for the sentence\n",
    "    bert_embedding = get_bert_embedding(sentence)  # Assuming a defined function\n",
    "\n",
    "    # Add temporal feature based on timestamp\n",
    "    try:\n",
    "        review_date = datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "        current_date = datetime.now()\n",
    "        temporal_feature = (current_date - review_date).days  # Time in days\n",
    "    except ValueError:\n",
    "        temporal_feature = 0  # Default value if timestamp parsing fails\n",
    "\n",
    "    # Combine features\n",
    "    vals = [\n",
    "        1,  # Bias term\n",
    "        book_pop,          # Book popularity\n",
    "        pop_by_freq,       # Popularity scaled by user frequency\n",
    "        user_rank,         # User ranking\n",
    "        user_rating,       # User's rating\n",
    "        temporal_feature,   # Temporal feature\n",
    "        ct_book_spoilers,\n",
    "        ct_user_spoilers,\n",
    "        avg_rating_item,\n",
    "        avg_rating_user\n",
    "    ]\n",
    "    \n",
    "    # Append BERT embeddings\n",
    "    vals.extend(bert_embedding.tolist())\n",
    "    \n",
    "    return vals\n",
    "\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for d in ratingsTrain:\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    print('new')\n",
    "    for sentence in d['review_sentences']:\n",
    "        bert_embedding = get_bert_embedding(sentence[1])\n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        x_train.append(filtered_data)\n",
    "        y_train.append(sentence[0])\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "for d in ratingsTrain:\n",
    "    print('newer')\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    for sentence in d['review_sentences']:\n",
    "        bert_embedding = get_bert_embedding(sentence[1])\n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        x_valid.append(filtered_data)\n",
    "        y_valid.append(sentence[0])\n",
    "        \n",
    "\n",
    "x_train = [create_vector(i) for i in x_train]\n",
    "x_valid = [create_vector(i) for i in x_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64d44ca7-10e9-4372-b23b-fbcbabeb5fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "done\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'28194' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#x_train = [create_vector(i) for i in x_train]\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m x_valid \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcreate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 114\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#x_train = [create_vector(i) for i in x_train]\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m x_valid \u001b[38;5;241m=\u001b[39m [\u001b[43mcreate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x_valid]\n",
      "Cell \u001b[0;32mIn[47], line 27\u001b[0m, in \u001b[0;36mcreate_vector\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m     25\u001b[0m user_freq \u001b[38;5;241m=\u001b[39m books_read_by_user[userIDs[u]]\n\u001b[1;32m     26\u001b[0m pop_by_freq \u001b[38;5;241m=\u001b[39m book_pop \u001b[38;5;241m*\u001b[39m user_freq\n\u001b[0;32m---> 27\u001b[0m book_rank \u001b[38;5;241m=\u001b[39m \u001b[43mPopularityBooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m user_rank \u001b[38;5;241m=\u001b[39m PopularityUsers\u001b[38;5;241m.\u001b[39mindex(u)\n\u001b[1;32m     29\u001b[0m ct_book_spoilers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(reviewsPerItem[b])\n",
      "\u001b[0;31mValueError\u001b[0m: '28194' is not in list"
     ]
    }
   ],
   "source": [
    "users = set(userIDs.keys())\n",
    "books = set(itemIDs.keys())\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def create_vector(review):\n",
    "    global users, books, avg_ct_book_spoilers, avg_ct_user_spoilers, ovr_avg_rating_item, ovr_avg_rating_user\n",
    "\n",
    "    u = review['user_id']\n",
    "    b = review['book_id']\n",
    "    timestamp = review['timestamp']\n",
    "    sentence = review['BERT_data']\n",
    "    rating = review['rating']\n",
    "    # Default feature values\n",
    "    book_in = b in books\n",
    "    user_in = u in users\n",
    "    if len(sentence) == 0:\n",
    "        sentence = np.zeros(768)  # Placeholder for BERT embedding\n",
    "    temporal_feature = 0           # Placeholder for temporal information\n",
    "    user_rating = rating if rating is not None else 0  # Use given rating\n",
    "\n",
    "    # Book and user interaction features\n",
    "    if book_in and user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = book_pop * user_freq\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        user_rank = PopularityUsers.index(u)\n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        avg_rating_user = ratingsPerUser[u]\n",
    "        avg_rating_user = sum(avg_rating_user) / len(avg_rating_user)\n",
    "    elif not user_in and not book_in:\n",
    "        book_pop = len(books)\n",
    "        user_freq = 0\n",
    "        pop_by_freq = 0\n",
    "        book_rank = len(books)\n",
    "        user_rank = len(users)\n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        avg_rating_user = ovr_avg_rating_user\n",
    "    elif not user_in:\n",
    "        book_pop = book_popularity[itemIDs[b]]\n",
    "        user_freq = 0\n",
    "        pop_by_freq = book_pop\n",
    "        book_rank = PopularityBooks.index(b)\n",
    "        user_rank = len(PopularityUsers)\n",
    "        ct_book_spoilers = sum(reviewsPerItem[b])\n",
    "        ct_user_spoilers = avg_ct_user_spoilers\n",
    "        avg_rating_item = ratingsPerItem[b]\n",
    "        avg_rating_item = sum(avg_rating_item) / len(avg_rating_item)\n",
    "        avg_rating_user = ovr_avg_rating_user\n",
    "    else:\n",
    "        book_pop = 0\n",
    "        user_freq = books_read_by_user[userIDs[u]]\n",
    "        pop_by_freq = user_freq\n",
    "        book_rank = len(PopularityBooks)\n",
    "        user_rank = PopularityUsers.index(u)\n",
    "        ct_book_spoilers = avg_ct_book_spoilers\n",
    "        ct_user_spoilers = sum(reviewsPerUser[u])\n",
    "        avg_rating_item = ovr_avg_rating_item\n",
    "        avg_rating_user = ratingsPerUser[u]\n",
    "        avg_rating_user = sum(avg_rating_user) / len(avg_rating_user)\n",
    "\n",
    "    # Add BERT embedding for the sentence\n",
    "    #bert_embedding = get_bert_embedding(sentence)  # Assuming a defined function\n",
    "\n",
    "    # Add temporal feature based on timestamp\n",
    "    try:\n",
    "        review_date = datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "        current_date = datetime.now()\n",
    "        temporal_feature = (current_date - review_date).days  # Time in days\n",
    "    except ValueError:\n",
    "        temporal_feature = 0  # Default value if timestamp parsing fails\n",
    "\n",
    "    # Combine features\n",
    "    vals = [\n",
    "        1,  # Bias term\n",
    "        book_pop,          # Book popularity\n",
    "        pop_by_freq,       # Popularity scaled by user frequency\n",
    "        user_rank,         # User ranking\n",
    "        user_rating,       # User's rating\n",
    "        temporal_feature,   # Temporal feature\n",
    "        ct_book_spoilers,\n",
    "        ct_user_spoilers,\n",
    "        avg_rating_item,\n",
    "        avg_rating_user\n",
    "    ]\n",
    "    \n",
    "    # Append BERT embeddings\n",
    "    vals.extend(sentence.tolist())\n",
    "    \n",
    "    return vals\n",
    "\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "ooooo = 0\n",
    "for d in ratingsTest[:100]:\n",
    "    if ooooo % 100 == 0: print(ooooo)\n",
    "    ooooo += 1\n",
    "    filtered_data = {key: value for key, value in d.items() if key != 'review_sentences' and key != 'has_spoiler'}\n",
    "    for sentence in d['review_sentences']:\n",
    "        bert_embedding = get_bert_embedding(sentence[1])\n",
    "        filtered_data['BERT_data'] = bert_embedding\n",
    "        x_valid.append(filtered_data)\n",
    "        y_valid.append(sentence[0])\n",
    "        \n",
    "print('done')\n",
    "#x_train = [create_vector(i) for i in x_train]\n",
    "x_valid_new = [create_vector(i) for i in x_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c07c416-1441-4f6c-8c67-a973c07091fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for d in ratingsTrain + ratingsTest:\n",
    "    bookCount[d['book_id']] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "PopularityBooks = [x[-1] for x in mostPopular]\n",
    "\n",
    "mostPopularUsers = [[len(value), key] for key, value in itemsPerUser.items()]\n",
    "mostPopularUsers.sort()\n",
    "mostPopularUsers.reverse()\n",
    "PopularityUsers = [x[-1] for x in mostPopularUsers]\n",
    "x_valid_new = [create_vector(i) for i in x_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19933ab0-a033-43e9-ab55-5853778609ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  1e-05\n",
      "accuracy:  0.9508408796895214\n",
      "tp:  0 tn:  735 fp:  24 fn:  14\n",
      "F1, precision + recall = 0\n",
      "AUC decision func: 0.7692923019009975\n",
      "AUC predict_proba: 0.7692923019009975\n",
      "First 1:  123\n",
      "Last 1:  264\n",
      "avg pct:  179.35714285714286\n",
      "C:  0.0001\n",
      "accuracy:  0.9508408796895214\n",
      "tp:  0 tn:  735 fp:  24 fn:  14\n",
      "F1, precision + recall = 0\n",
      "AUC decision func: 0.8319687558817993\n",
      "AUC predict_proba: 0.8322510822510822\n",
      "First 1:  42\n",
      "Last 1:  163\n",
      "avg pct:  131.64285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.001\n",
      "accuracy:  0.9534282018111255\n",
      "tp:  1 tn:  736 fp:  23 fn:  13\n",
      "F1:  0.052631578947368425\n",
      "AUC decision func: 0.8519198193111236\n",
      "AUC predict_proba: 0.8516374929418409\n",
      "First 1:  6\n",
      "Last 1:  139\n",
      "avg pct:  116.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.01\n",
      "accuracy:  0.9534282018111255\n",
      "tp:  1 tn:  736 fp:  23 fn:  13\n",
      "F1:  0.052631578947368425\n",
      "AUC decision func: 0.8602955015998494\n",
      "AUC predict_proba: 0.8602955015998494\n",
      "First 1:  21\n",
      "Last 1:  150\n",
      "avg pct:  110.28571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.1\n",
      "accuracy:  0.9534282018111255\n",
      "tp:  1 tn:  736 fp:  23 fn:  13\n",
      "F1:  0.052631578947368425\n",
      "AUC decision func: 0.791690193864107\n",
      "AUC predict_proba: 0.7919725202333898\n",
      "First 1:  10\n",
      "Last 1:  241\n",
      "avg pct:  162.21428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  1\n",
      "accuracy:  0.9534282018111255\n",
      "tp:  1 tn:  736 fp:  23 fn:  13\n",
      "F1:  0.052631578947368425\n",
      "AUC decision func: 0.7653397327310371\n",
      "AUC predict_proba: 0.76562205910032\n",
      "First 1:  10\n",
      "Last 1:  276\n",
      "avg pct:  182.21428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  10\n",
      "accuracy:  0.9534282018111255\n",
      "tp:  1 tn:  736 fp:  23 fn:  13\n",
      "F1:  0.052631578947368425\n",
      "AUC decision func: 0.788772821381517\n",
      "AUC predict_proba: 0.788772821381517\n",
      "First 1:  9\n",
      "Last 1:  244\n",
      "avg pct:  164.57142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  100\n",
      "accuracy:  0.9534282018111255\n",
      "tp:  1 tn:  736 fp:  23 fn:  13\n",
      "F1:  0.052631578947368425\n",
      "AUC decision func: 0.8775174101261057\n",
      "AUC predict_proba: 0.8777997364953887\n",
      "First 1:  6\n",
      "Last 1:  150\n",
      "avg pct:  97.07142857142857\n"
     ]
    }
   ],
   "source": [
    "#percentile_80_second = np.percentile(x_train[:, 1], 95)\n",
    "#percentile_95_third = np.percentile(x_train[:, 2], 95)\n",
    "##percentile_95_four = np.percentile(x_train[:, 3], 95)\n",
    "\n",
    "#filtered_indices = np.where((x_train[:, 1] < percentile_80_second) & (x_train[:, 2] < percentile_95_third) & (x_train[:, 3] < percentile_95_four))[0]\n",
    "#c=100 the best\n",
    "#x_train_filtered = x_train[filtered_indices]\n",
    "#y_train_filtered = np.array(y_train)[filtered_indices]\n",
    "for c in [.00001, .0001, .001, .01, .1, 1, 10, 100]:\n",
    "    mod = linear_model.LogisticRegression(C=c, class_weight = 'balanced')\n",
    "    mod.fit(x_train,y_train)\n",
    "    scores = mod.decision_function(x_valid_new)\n",
    "    new_results = {index: score for index, score in enumerate(scores)}     \n",
    "    sorted_items = sorted(new_results.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    pred = np.zeros(len(x_valid_new))\n",
    "    if len(x_valid_new) % 2 == 1:\n",
    "        for i in sorted_items[:int(3 * len(x_valid_new)//100) + 1]:\n",
    "            pred[i[0]] = 1\n",
    "    else:\n",
    "        for i in sorted_items[:int(3 * len(x_valid_new)//100)]:\n",
    "            pred[i[0]] = 1\n",
    "    \n",
    "    corr = 0\n",
    "    tn, tp, fn, fp = 0,0,0,0\n",
    "    for guess, actual in zip(pred, y_valid):\n",
    "        if guess == actual:\n",
    "            corr += 1\n",
    "            if guess == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        else:\n",
    "            if guess == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    \n",
    "    curr_counter = 0\n",
    "    all_pos = 0\n",
    "    first_one = 0\n",
    "    last_one = 0\n",
    "    got_one = False\n",
    "    got_all = 0\n",
    "    while got_one < 14 and curr_counter < len(sorted_items):\n",
    "        if y_valid[sorted_items[curr_counter][0]] == 1:\n",
    "            got_all += 1\n",
    "            if got_all == 14:\n",
    "                last_one = curr_counter\n",
    "            all_pos += curr_counter\n",
    "            if got_one == False:\n",
    "                got_one = True \n",
    "                first_one = curr_counter\n",
    "        curr_counter += 1\n",
    "    print(\"C: \", c)\n",
    "    get_metric(y_valid, pred, scores, mod.predict_proba(x_valid_new)[:,1])\n",
    "    print(\"First 1: \", first_one)\n",
    "    print(\"Last 1: \", last_one)\n",
    "    print(\"avg pct: \", all_pos / 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "272f639b-d05c-411f-bf91-b2c8ea824792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12548512289780078"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "97 / len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08ed7e31-c518-405b-9824-44caf9256165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb6897d1-48bf-488f-906f-bbba3ef5b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "#first_one = 0\n",
    "got_one = False\n",
    "for first_one in range(len(sorted_items)):\n",
    "    if y_valid[sorted_items[first_one][0]] == 1:\n",
    "        got_one = True\n",
    "        print(first_one)\n",
    "    else:\n",
    "        first_one += 1\n",
    "#first_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f58bba34-1ad8-42f0-a2fd-9d7e7121c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2108667529107374"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "163 / len(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2fe3a4d-c9e5-4d70-b2c6-4c54850f3b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "scores = mod.decision_function(x_valid_new)\n",
    "new_results = {index: score for index, score in enumerate(scores)}     \n",
    "sorted_items = sorted(new_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pred = np.zeros(len(x_valid_new))\n",
    "if len(x_valid_new) % 2 == 1:\n",
    "    for i in sorted_items[:int(3 * len(x_valid_new)//100) + 1]:\n",
    "        pred[i[0]] = 1\n",
    "else:\n",
    "    for i in sorted_items[:int(3 * len(x_valid_new)//100)]:\n",
    "        pred[i[0]] = 1\n",
    "\n",
    "corr = 0\n",
    "tn, tp, fn, fp = 0,0,0,0\n",
    "for guess, actual in zip(pred, y_valid):\n",
    "    if guess == actual:\n",
    "        corr += 1\n",
    "        if guess == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    else:\n",
    "        if guess == 0:\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    if actual == 1:\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff7aece1-8aae-437f-b737-9b4b23ff030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9508408796895214\n",
      "tp:  0 tn:  735 fp:  24 fn:  14\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", corr / len(pred))\n",
    "print(\"tp: \", tp, \"tn: \", tn, \"fp: \", fp, \"fn: \", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30e89f8f-1e07-48d9-b4d4-c5d312da939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def get_metric(y_true, pred, scores, scores2):\n",
    "    corr = 0\n",
    "    tn, tp, fn, fp = 0,0,0,0\n",
    "    for guess, actual in zip(pred, y_true):\n",
    "        if guess == actual:\n",
    "            corr += 1\n",
    "            if guess == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        else:\n",
    "            if guess == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    if tp + fp == 0:\n",
    "        precision = 0\n",
    "        print(\"precision, tp + fp = 0\")\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "        print(\"recall, tp + fn = 0\")\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    print(\"accuracy: \", corr / len(pred))\n",
    "    print(\"tp: \", tp, \"tn: \", tn, \"fp: \", fp, \"fn: \", fn)\n",
    "    # Calculate F1 Score\n",
    "    if precision + recall == 0:\n",
    "        print(\"F1, precision + recall = 0\")\n",
    "    else:\n",
    "        print(\"F1: \", 2 * (precision * recall) / (precision + recall))\n",
    "    auc = roc_auc_score(y_valid, scores)\n",
    "    print(f\"AUC decision func: {auc}\")\n",
    "    auc = roc_auc_score(y_valid, scores2)\n",
    "    print(f\"AUC predict_proba: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c39fbfcc-38ff-489d-9ff9-445794e3692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7611989459815547\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: True labels and predicted probabilities\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_valid, scores)\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, scores)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")  # Random guessing line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4f40ee3-d844-4a1e-8170-fb2c6c268117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981888745148771 0 759 0 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "mod = linear_model.LogisticRegression(C=100, class_weight = 'balanced')\n",
    "# Fit the logistic regression model\n",
    "mod.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities on test data\n",
    "probabilities = mod.predict_proba(x_valid_new)[:, 1]\n",
    "\n",
    "# Calibrate probabilities\n",
    "true_positive_rate = 0.035  # 2.5% of test data\n",
    "balanced_positive_rate = 0.5  # 50% in training\n",
    "calibrated_probabilities = probabilities * (true_positive_rate / balanced_positive_rate)\n",
    "\n",
    "# Adjust threshold (optional)\n",
    "threshold = 0.05  # Example threshold, tune based on validation set\n",
    "predictions = (calibrated_probabilities >= threshold).astype(int)\n",
    " \n",
    "corr = 0\n",
    "tn, tp, fn, fp = 0,0,0,0\n",
    "for guess, actual in zip(predictions, y_valid):\n",
    "    if guess == actual:\n",
    "        corr += 1\n",
    "        if guess == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    else:\n",
    "        if guess == 0:\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "print(corr / len(predictions), tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48187b82-0ddd-46e8-8cfc-4824ecad331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the variable in the training data\n",
    "train_variable_adjusted = train_variable + (test_avg - train_avg)\n",
    "\n",
    "# Fit the model with adjusted training data\n",
    "model.fit(X_train.assign(variable=train_variable_adjusted), y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c08ee-2976-495e-8b2f-deb8fca3f6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6affd-b0c8-4ac1-8219-d9baf54270ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21442860-3e86-4ee7-9a18-f15d0760809b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f861c94-a311-466e-a75a-1427a3505b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRY TWO\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Tokenizer and Model setup\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "classification_layer = torch.nn.Linear(2 + 2, 1)\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(review):\n",
    "    sentences = review['review_sentences']\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Tokenize sentences and pad them\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    for sentence_data in sentences:\n",
    "        label, sentence = sentence_data\n",
    "        # Tokenize each sentence\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512)\n",
    "        \n",
    "        all_input_ids.append(inputs['input_ids'])\n",
    "        all_attention_masks.append(inputs['attention_mask'])\n",
    "        \n",
    "        # Additional features (temporal feature and revelatory feature)\n",
    "        temporal_feature = sentences.index(sentence_data) / len(sentences)\n",
    "        revelatory_keywords = [\"reveal\", \"unveil\", \"discover\", \"end\", \"surprise\", \"plot twist\"]\n",
    "        revelatory_feature = int(any(keyword in sentence.lower() for keyword in revelatory_keywords))\n",
    "        \n",
    "        # Add extra features for each sentence\n",
    "        features.append({\n",
    "            'temporal_feature': torch.tensor([temporal_feature], dtype=torch.float32),\n",
    "            'revelatory_feature': torch.tensor([revelatory_feature], dtype=torch.float32)\n",
    "        })\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Convert to tensors and pad input tensors\n",
    "    input_ids = torch.cat(all_input_ids, dim=0)\n",
    "    attention_masks = torch.cat(all_attention_masks, dim=0)\n",
    "    \n",
    "    return features, labels, input_ids, attention_masks\n",
    "\n",
    "# Custom Dataset for review sentences\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.input_ids = []\n",
    "        self.attention_masks = []\n",
    "        \n",
    "        # Process each review\n",
    "        for review in data:\n",
    "            review_features, review_labels, review_input_ids, review_attention_masks = extract_features(review)\n",
    "            self.features.extend(review_features)\n",
    "            self.labels.extend(review_labels)\n",
    "            self.input_ids.extend(review_input_ids)\n",
    "            self.attention_masks.extend(review_attention_masks)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'temporal_feature': self.features[idx]['temporal_feature'],\n",
    "            'revelatory_feature': self.features[idx]['revelatory_feature'],\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# DataLoader for batching\n",
    "dataset = ReviewDataset(testing_data)\n",
    "dataloader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(classification_layer.parameters()), lr=1e-5)\n",
    "\n",
    "# Training Loop (simplified)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1):  # Number of epochs\n",
    "    print(\"EPOCH: \", epoch)\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        temporal_feature = batch['temporal_feature']\n",
    "        revelatory_feature = batch['revelatory_feature']\n",
    "        \n",
    "        # BERT outputs\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        combined_features = torch.cat([logits, temporal_feature, revelatory_feature], dim=1)  # Shape: [batch_size, num_labels + 2]\n",
    "\n",
    "        # Pass through the classification layer\n",
    "        predictions = classification_layer(combined_features).squeeze(1)  # Shape: [batch_size]\n",
    "        #print(predictions)\n",
    "        # Calculate loss (remove double sigmoid application)\n",
    "        labels = batch['label'].float()  # Ensure labels are of shape [batch_size]\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(predictions, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "# Prediction function\n",
    "def predict_spoiler(sentence, review_data):\n",
    "    model.eval()\n",
    "    tokenizer_input = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    temporal_feature = torch.tensor([[len(review_data['review_sentences']) / 2]], dtype=torch.float32)  # Simplified example\n",
    "    revelatory_feature = torch.tensor([[int(any(keyword in sentence.lower() for keyword in [\"reveal\", \"unveil\", \"discover\"]))]], dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # BERT logits\n",
    "        outputs = model(input_ids=tokenizer_input['input_ids'], attention_mask=tokenizer_input['attention_mask'])\n",
    "        logits = outputs.logits  # Shape: [1, num_labels]\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([logits, temporal_feature, revelatory_feature], dim=1)  # Shape: [1, num_labels + 2]\n",
    "        \n",
    "        # Pass through classification layer\n",
    "        predictions = classification_layer(combined_features).squeeze(1)  # Shape: [1]\n",
    "        probability = torch.sigmoid(predictions).item()  # Convert to scalar\n",
    "        \n",
    "    return probability > 0.5  # Return True if spoiler, False otherwise\n",
    "\n",
    "# Testing the model accuracy\n",
    "ct = 0\n",
    "ovr = 0\n",
    "# Test the model on the first review\n",
    "for review in data[125:133]:\n",
    "    for sentence_data in review['review_sentences']:\n",
    "        ovr += 1\n",
    "        sentence = sentence_data[1]\n",
    "        is_spoiler = predict_spoiler(sentence, review)\n",
    "        if int(is_spoiler) == sentence_data[0]:\n",
    "            ct += 1\n",
    "ct / ovr  # Print the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
